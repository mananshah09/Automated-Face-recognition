{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"FaceNet_face_embedings.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMiXRLkLyhgwVR6OmguLQEf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"7zTCzDe8TMlJ","executionInfo":{"status":"ok","timestamp":1632208009142,"user_tz":-330,"elapsed":3226,"user":{"displayName":"8953 Brendan Lucas","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15493160506150931701"}}},"source":["# calculate a face embedding for each face in the dataset using facenet\n","from numpy import load\n","from numpy import expand_dims\n","from numpy import asarray\n","from numpy import savez_compressed\n","from keras.models import load_model\n","import tensorflow as tf"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LdkCY6beTwdT","executionInfo":{"status":"ok","timestamp":1632208059246,"user_tz":-330,"elapsed":46638,"user":{"displayName":"8953 Brendan Lucas","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15493160506150931701"}},"outputId":"308383ff-2e01-455a-8fec-4473395aa8f6"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tr7rd_QetUne","executionInfo":{"status":"ok","timestamp":1632208070780,"user_tz":-330,"elapsed":3711,"user":{"displayName":"8953 Brendan Lucas","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15493160506150931701"}},"outputId":"edde3013-ff7b-4129-c3da-1ec25bc1de1a"},"source":["pip install --index-url https://google-coral.github.io/py-repo/ tflite_runtime"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://google-coral.github.io/py-repo/\n","Collecting tflite_runtime\n","  Downloading https://github.com/google-coral/pycoral/releases/download/v2.0.0/tflite_runtime-2.5.0.post1-cp37-cp37m-linux_x86_64.whl (1.5 MB)\n","\u001b[K     |████████████████████████████████| 1.5 MB 27.6 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tflite_runtime) (1.19.5)\n","Installing collected packages: tflite-runtime\n","Successfully installed tflite-runtime-2.5.0.post1\n"]}]},{"cell_type":"code","metadata":{"id":"vbC7XCzxtYzW","executionInfo":{"status":"ok","timestamp":1632208074196,"user_tz":-330,"elapsed":2,"user":{"displayName":"8953 Brendan Lucas","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15493160506150931701"}}},"source":["from tflite_runtime.interpreter import Interpreter \n","from PIL import Image\n","import numpy as np\n","import time\n","import matplotlib.pyplot"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"uuOEH--nUMY7","executionInfo":{"status":"ok","timestamp":1632208089263,"user_tz":-330,"elapsed":632,"user":{"displayName":"8953 Brendan Lucas","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15493160506150931701"}}},"source":["# get the face embedding for one face\n","def get_embedding(model, face_pixels):\n","\t# scale pixel values\n","\tface_pixels = face_pixels.astype('float32')\n","\t# standardize pixel values across channels (global)\n","\tmean, std = face_pixels.mean(), face_pixels.std()\n","\tface_pixels = (face_pixels - mean) / std\n","\t# transform face into one sample\n","\tsamples = expand_dims(face_pixels, axis=0)\n","\t# make prediction to get embedding\n","\tyhat = model.predict(samples)\n","\treturn yhat[0]"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1EcmUms_UQ-s","executionInfo":{"status":"ok","timestamp":1632208283532,"user_tz":-330,"elapsed":168098,"user":{"displayName":"8953 Brendan Lucas","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15493160506150931701"}},"outputId":"9041a7c0-20af-4e0a-9c04-bc059a784c61"},"source":["# load the face dataset\n","data = load('/content/drive/MyDrive/data/image-recogination/faces-dataset10.npz',allow_pickle=True)\n","trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n","print('Loaded: ', trainX.shape, trainy.shape, testX.shape, testy.shape)\n","# load the facenet model\n","model = load_model('/content/drive/MyDrive/Colab Notebooks/facenet_keras.h5')\n","print('Loaded Model')\n","# convert each face in the train set to an embedding\n","newTrainX = list()\n","for face_pixels in trainX:\n","\tembedding = get_embedding(model, face_pixels)\n","\tnewTrainX.append(embedding)\n","newTrainX = asarray(newTrainX)\n","print(newTrainX.shape)\n","# convert each face in the test set to an embedding\n","newTestX = list()\n","for face_pixels in testX:\n","\tembedding = get_embedding(model, face_pixels)\n","\tnewTestX.append(embedding)\n","newTestX = asarray(newTestX)\n","print(newTestX.shape)\n","# save arrays to one file in compressed format\n","savez_compressed('/content/drive/MyDrive/data/image-recogination/faces-embeddings8.npz', newTrainX, trainy, newTestX, testy)"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded:  (605, 160, 160, 3) (605,) (506, 160, 160, 3) (506,)\n","WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","Loaded Model\n","(605, 128)\n","(506, 128)\n"]}]},{"cell_type":"code","metadata":{"id":"yiOErvaBCeXa"},"source":["def set_input_tensor2(image):\n","  tensor_index = interpreter.get_input_details()[0]['index']\n","  # print(\"Index of the input tensor: \", tensor_index, end=\"\\n\\n\")\n","  # Return the input tensor based on its index.\n","  input_tensor = interpreter.tensor(tensor_index)()[0]\n","  # Assigning the image to the input tensor.\n","  print(asarray(image).shape)\n","  input_tensor[:, :] = image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ywmIrgrVLQ_8"},"source":["def set_input_tensor(face_pixels):\n","  tensor_index = interpreter.get_input_details()[0]['index']\n","  # print(\"Index of the input tensor: \", tensor_index, end=\"\\n\\n\")\n","  # Return the input tensor based on its index.\n","  input_tensor = interpreter.tensor(tensor_index)()[0]\n","  # Assigning the image to the input tensor.\n","  face_pixels = face_pixels.astype('float32')\n","  # standardize pixel values across channels (global)\n","  mean, std = face_pixels.mean(), face_pixels.std()\n","  face_pixels = (face_pixels - mean) / std\n","  # print(face_pixels.shape)\n","  samples = expand_dims(face_pixels, axis=0)\n","  # transform face into one sample\n","  # face_pixels = (face_pixels * 255).astype(np.uint8)\n","  image = Image.fromarray(face_pixels.astype(np.uint8))\n","  input_tensor[:, :] = image\n","  interpreter.invoke()\n","  output_details = interpreter.get_output_details()[0]\n","  # print(\"Details about the input tensors:\\n   \", output_details, end=\"\\n\\n\")\n","  scores = interpreter.get_tensor(output_details['index'])\n","  # print(scores[0].shape)\n","  return scores[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_b1ORTV7ur7N","executionInfo":{"status":"ok","timestamp":1632208654106,"user_tz":-330,"elapsed":684,"user":{"displayName":"8953 Brendan Lucas","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15493160506150931701"}}},"source":["def set_input_tensor3(face_pixels):\n","  # scale pixel values\n","  face_pixels = asarray(face_pixels)\n","  face_pixels = face_pixels.astype(np.uint8)\n","\t# standardize pixel values across channels (global)\n","  mean, std = face_pixels.mean(), face_pixels.std()\n","  face_pixels = (face_pixels - mean) / std\n","\t# transform face into one sample\n","  samples = expand_dims(face_pixels, axis=0)\n","\t# make prediction to get embedding\n","  tensor_index = interpreter.get_input_details()[0]['index']\n","  # print(\"Index of the input tensor: \", tensor_index, end=\"\\n\\n\")\n","  # Return the input tensor based on its index.\n","  # print(samples.shape)\n","  input_tensor = interpreter.tensor(tensor_index)()[0]\n","  input_tensor[:, :] = samples"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"JYuNBH3QCeCQ","executionInfo":{"status":"ok","timestamp":1632208657708,"user_tz":-330,"elapsed":389,"user":{"displayName":"8953 Brendan Lucas","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15493160506150931701"}}},"source":["def classify_image():\n","  # Call the invoke() method from inside a function to avoid this RuntimeError: reference to internal data in the interpreter in the form of a numpy array or slice.\n","  interpreter.invoke()\n","  output_details = interpreter.get_output_details()[0]\n","  # print(\"Details about the input tensors:\\n   \", output_details, end=\"\\n\\n\")\n","  scores = interpreter.get_tensor(output_details['index'])\n","  # print(scores[0].shape)\n","  return scores[0]"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nzb4H78XzKux"},"source":["tensor_index = interpreter.get_input_details()[0]['index']\n","input_tensor_z= tf.convert_to_tensor(z, np.float32)\n","interpreter.set_tensor(tensor_index, input_tensor_z)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IfI4S8sdysI0"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":162},"id":"617o666aysBY","executionInfo":{"status":"error","timestamp":1632168016595,"user_tz":-330,"elapsed":591,"user":{"displayName":"8953 Brendan Lucas","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15493160506150931701"}},"outputId":"ec4be759-382e-42d1-e3af-f7be6ca61f01"},"source":[""],"execution_count":null,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-047ed65ff157>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'NpzFile' object has no attribute 'shape'"]}]},{"cell_type":"code","metadata":{"id":"n-G78D25CdRJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632208881276,"user_tz":-330,"elapsed":219165,"user":{"displayName":"8953 Brendan Lucas","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15493160506150931701"}},"outputId":"3d5429fe-563f-4200-860d-f4744ca80b8a"},"source":["# load the face dataset\n","data = load('/content/drive/MyDrive/data/image-recogination/faces-dataset10.npz',allow_pickle=True)\n","trainX, trainy, testX, testy = data['arr_0'], data['arr_1'], data['arr_2'], data['arr_3']\n","print('Loaded: ', trainX.shape, trainy.shape, testX.shape, testy.shape)\n","# load the facenet model\n","model_path =\"/content/drive/MyDrive/data/image-recogination/facenet_model.tflite\"\n","interpreter = Interpreter(model_path)\n","interpreter.allocate_tensors()\n","print(\"Model Loaded Successfully.\")\n","# convert each face in the train set to an embedding\n","newTrainX = list()\n","for face_pixels in trainX:\n","\t\timage = Image.fromarray(face_pixels.astype(np.uint8))\n","\t\tset_input_tensor3(image)\n","\t\tembedding = classify_image()\n","\t\tnewTrainX.append(embedding)\n","newTrainX = asarray(newTrainX)\n","print(newTrainX.shape)\n","# convert each face in the test set to an embedding\n","# model_path =\"/content/drive/MyDrive/data/image-recogination/facenet_model.tflite\"\n","# interpreter = Interpreter(model_path)\n","# interpreter.allocate_tensors()\n","# print(\"Model Loaded Successfully.\")\n","newTestX = list()\n","for face_pixels in testX:\n","\t\timage = Image.fromarray(face_pixels.astype(np.uint8))\n","\t\tset_input_tensor3(image)\n","\t\tembedding = classify_image()\n","\t\tnewTestX.append(embedding)\n","newTestX = asarray(newTestX)\n","print(newTestX.shape)\n","# save arrays to one file in compressed format\n","savez_compressed('/content/drive/MyDrive/data/image-recogination/faces-embeddings9.npz', newTrainX, trainy, newTestX, testy)"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded:  (605, 160, 160, 3) (605,) (506, 160, 160, 3) (506,)\n","Model Loaded Successfully.\n","(605, 128)\n","(506, 128)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":128},"id":"IW4zNh-YNeDl","executionInfo":{"status":"error","timestamp":1632124751967,"user_tz":-330,"elapsed":619,"user":{"displayName":"8953 Brendan Lucas","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15493160506150931701"}},"outputId":"98e27179-e413-4469-ab09-98def05d9dfe"},"source":["newTestX.shape"],"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-30-300519ce7592>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    newTestX[][0].shape\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","metadata":{"id":"Y8QY6tgoFxS6"},"source":["model = load_model('/content/drive/MyDrive/Colab Notebooks/facenet_keras.h5', compile=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-QQbMgR5FDHM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631820745118,"user_tz":-330,"elapsed":64990,"user":{"displayName":"8953 Brendan Lucas","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15493160506150931701"}},"outputId":"efd5268d-c053-4c31-aed7-5957ff998800"},"source":["tf_lite_converter = tf.lite.TFLiteConverter.from_keras_model(model)\n","tflite_model = tf_lite_converter.convert()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","INFO:tensorflow:Assets written to: /tmp/tmpu4n9is7v/assets\n"]}]},{"cell_type":"code","metadata":{"id":"HnUTPFnfMYcV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631820803917,"user_tz":-330,"elapsed":1045,"user":{"displayName":"8953 Brendan Lucas","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15493160506150931701"}},"outputId":"34014120-384d-4c66-f4a6-8d5436c6b8a9"},"source":["tflite_model_name = \"facenet_model_tensorflowlite.tflite\"\n","dir_loc = \"/content/drive/MyDrive/data/image-recogination/\"\n","open(dir_loc+tflite_model_name, \"wb\").write(tflite_model)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["91221556"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7b_4vpXzmmnr","executionInfo":{"status":"ok","timestamp":1631947056519,"user_tz":-330,"elapsed":76855,"user":{"displayName":"8953 Brendan Lucas","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15493160506150931701"}},"outputId":"6f759fb5-2904-44d5-c880-f751a0bbe80d"},"source":["import tensorflow.lite as lite\n","import tensorflow as tf\n","\n","input_file = \"/content/drive/MyDrive/Colab Notebooks/facenet_keras.h5\"\n","output_file = \"/content/drive/MyDrive/Colab Notebooks/facenet_keras_lite.tflite\"\n","\n","# Converts the Keras model to TensorFlow Lite\n","model = tf.keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/facenet_keras.h5')\n","converter = lite.TFLiteConverter.from_keras_model(model)\n","converter.post_training_quantize = True\n","tflite_model = converter.convert()\n","open(output_file, \"wb\").write(tflite_model)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","INFO:tensorflow:Assets written to: /tmp/tmpgmoeo95l/assets\n"]},{"output_type":"execute_result","data":{"text/plain":["91221556"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6VuHM-zjRoUm","executionInfo":{"status":"ok","timestamp":1632168107078,"user_tz":-330,"elapsed":4339,"user":{"displayName":"8953 Brendan Lucas","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15493160506150931701"}},"outputId":"8dec2cc0-1fec-4383-e613-33b8b9e42489"},"source":["pip install --index-url https://google-coral.github.io/py-repo/ tflite_runtime"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://google-coral.github.io/py-repo/\n","Collecting tflite_runtime\n","  Downloading https://github.com/google-coral/pycoral/releases/download/v2.0.0/tflite_runtime-2.5.0.post1-cp37-cp37m-linux_x86_64.whl (1.5 MB)\n","\u001b[K     |████████████████████████████████| 1.5 MB 34.1 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tflite_runtime) (1.19.5)\n","Installing collected packages: tflite-runtime\n","Successfully installed tflite-runtime-2.5.0.post1\n"]}]},{"cell_type":"code","metadata":{"id":"K6CmwlfGn55x"},"source":["from tflite_runtime.interpreter import Interpreter \n","from PIL import Image\n","import numpy as np\n","import time\n","import matplotlib.pyplot"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_QtejQSNStbV","executionInfo":{"status":"ok","timestamp":1631996601406,"user_tz":-330,"elapsed":563,"user":{"displayName":"8953 Brendan Lucas","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15493160506150931701"}},"outputId":"db5c9ca6-d717-477b-ddc6-22c355e68536"},"source":["model_path =\"/content/drive/MyDrive/data/image-recogination/facenet_model.tflite\"\n","\n","interpreter = Interpreter(model_path)\n","print(\"Model Loaded Successfully.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model Loaded Successfully.\n"]}]},{"cell_type":"code","metadata":{"id":"rE6rGkthTCMf"},"source":["interpreter.allocate_tensors()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7n7yjTjfTFnk","executionInfo":{"status":"ok","timestamp":1631992051081,"user_tz":-330,"elapsed":679,"user":{"displayName":"8953 Brendan Lucas","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15493160506150931701"}},"outputId":"a9a71111-4637-4fbf-a415-4b41d81e061e"},"source":["print(\"Details about the input tensors:\\n   \", interpreter.get_input_details())\n","print(\"There exist {num} input tensor(s).\".format(num=len(interpreter.get_input_details())))\n","print(\"   Type:\", type(interpreter.get_input_details()), end=\"\\n\\n\")\n","\n","print(\"Details about the first input tensor:\\n  \", interpreter.get_input_details()[0])\n","print(\"   Type:\", type(interpreter.get_input_details()[0]), end=\"\\n\\n\")\n","\n","print(\"Shape of the first input tensor:\\n   \", interpreter.get_input_details()[0]['shape'])\n","print(\"   Type:\", type(interpreter.get_input_details()[0]['shape']), end=\"\\n\\n\")\n","\n","_, height, width, _ = interpreter.get_input_details()[0]['shape']\n","print(\"Image Width = {width}\\nImage Height = {height}\".format(width=width, height=height))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Details about the input tensors:\n","    [{'name': 'input_2', 'index': 0, 'shape': array([  1, 160, 160,   3], dtype=int32), 'shape_signature': array([ -1, 160, 160,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n","There exist 1 input tensor(s).\n","   Type: <class 'list'>\n","\n","Details about the first input tensor:\n","   {'name': 'input_2', 'index': 0, 'shape': array([  1, 160, 160,   3], dtype=int32), 'shape_signature': array([ -1, 160, 160,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n","   Type: <class 'dict'>\n","\n","Shape of the first input tensor:\n","    [  1 160 160   3]\n","   Type: <class 'numpy.ndarray'>\n","\n","Image Width = 160\n","Image Height = 160\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uAvsYd8MT6Ek","executionInfo":{"status":"ok","timestamp":1631996614530,"user_tz":-330,"elapsed":543,"user":{"displayName":"8953 Brendan Lucas","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15493160506150931701"}},"outputId":"d13744b0-8877-4ddf-8477-b75d03484376"},"source":["# Note: if no image present, upload your own test image as \"test.jpg\" to the mobilenet_v1 folder\n","image = Image.open(\"/content/drive/MyDrive/data/image-recogination/ananya/gray_faces/ananya-0.jpg_0_1725-0.jpeg\").convert('RGB')\n","print(\"Original image size:\", image.size)\n","\n","image = image.resize((160, 160))\n","print(\"New size:\", image.size)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Original image size: (373, 373)\n","New size: (160, 160)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nFr9z_xPd62H","executionInfo":{"status":"ok","timestamp":1631994921807,"user_tz":-330,"elapsed":6,"user":{"displayName":"8953 Brendan Lucas","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15493160506150931701"}},"outputId":"966a82f4-116b-4f60-ad39-a571aa4f7d95"},"source":["tensor_index = interpreter.get_input_details()[0]['index']\n","print(\"Index of the input tensor: \", tensor_index, end=\"\\n\\n\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Index of the input tensor:  0\n","\n"]}]},{"cell_type":"code","metadata":{"id":"44E25uF6eAuw"},"source":["# Return the input tensor based on its index.\n","input_tensor = interpreter.tensor(tensor_index)()[0]\n","input_tensor[:, :] = image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vzB2_oKnT0qH"},"source":["def set_input_tensor(interpreter, image):\n","\n","  tensor_index = interpreter.get_input_details()[0]['index']\n","  print(\"Index of the input tensor: \", tensor_index, end=\"\\n\\n\")\n","\n","  # Return the input tensor based on its index.\n","  input_tensor = interpreter.tensor(tensor_index)()[0]\n","\n","  matplotlib.pyplot.subplots(nrows=1, ncols=2)\n","  matplotlib.pyplot.subplot(121)\n","  matplotlib.pyplot.imshow(input_tensor)\n","  matplotlib.pyplot.title(\"Before\")\n","\n","  # Assigning the image to the input tensor.\n","  input_tensor[:, :] = image\n","\n","  matplotlib.pyplot.subplot(122)\n","  matplotlib.pyplot.imshow(input_tensor)\n","  matplotlib.pyplot.title(\"After\")\n","  matplotlib.pyplot.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":283},"id":"11BdszPkUJXc","executionInfo":{"status":"ok","timestamp":1631992286380,"user_tz":-330,"elapsed":466,"user":{"displayName":"8953 Brendan Lucas","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15493160506150931701"}},"outputId":"6ab4b24d-e2f3-47a6-b668-ada34b0ff7f6"},"source":["set_input_tensor(interpreter, image)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n","Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"]},{"output_type":"stream","name":"stdout","text":["Index of the input tensor:  0\n","\n"]},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"-s72v3KQUWft"},"source":["def classify_image(interpreter, image):\n","\n","  # Call the invoke() method from inside a function to avoid this RuntimeError: reference to internal data in the interpreter in the form of a numpy array or slice.\n","  interpreter.invoke()\n","\n","  output_details = interpreter.get_output_details()[0]\n","  print(\"Details about the input tensors:\\n   \", output_details, end=\"\\n\\n\")\n","\n","  scores = interpreter.get_tensor(output_details['index'])[0]\n","  print(\"Predicted class label score      =\", np.max(np.unique(scores)))\n","\n","  # Dequantize the scores.\n","  scale, zero_point = output_details['quantization']\n","  scores_dequantized = scale * (scores - zero_point)\n","\n","  dequantized_max_score = np.max(np.unique(scores_dequantized))\n","  print(\"Predicted class label probability=\", dequantized_max_score, end=\"\\n\\n\")\n","\n","  max_score_index = np.where(scores_dequantized == np.max(np.unique(scores_dequantized)))[0][0]\n","  print(\"Predicted class label ID=\", max_score_index)\n","\n","  return max_score_index, dequantized_max_score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jYO3tjx2U3Sn","executionInfo":{"status":"ok","timestamp":1631992382253,"user_tz":-330,"elapsed":644,"user":{"displayName":"8953 Brendan Lucas","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15493160506150931701"}},"outputId":"0f227c87-a963-40f6-8d11-380e3734f792"},"source":["label_id, prob = classify_image(interpreter, image)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Details about the input tensors:\n","    {'name': 'Identity', 'index': 456, 'shape': array([  1, 128], dtype=int32), 'shape_signature': array([ -1, 128], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n","\n","Predicted class label score      = 2.6459787\n","Predicted class label probability= -0.0\n","\n","Predicted class label ID= 0\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yv0k0bGOYSBN","executionInfo":{"status":"ok","timestamp":1631995054175,"user_tz":-330,"elapsed":1289,"user":{"displayName":"8953 Brendan Lucas","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15493160506150931701"}},"outputId":"9c5a669d-407d-47ee-acf7-051bfd51ab59"},"source":["interpreter.invoke()\n","\n","output_details = interpreter.get_output_details()[0]\n","print(\"Details about the input tensors:\\n   \", output_details, end=\"\\n\\n\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Details about the input tensors:\n","    {'name': 'Identity', 'index': 456, 'shape': array([  1, 128], dtype=int32), 'shape_signature': array([ -1, 128], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zgu_FmTzYV7L","executionInfo":{"status":"ok","timestamp":1631995057761,"user_tz":-330,"elapsed":670,"user":{"displayName":"8953 Brendan Lucas","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15493160506150931701"}},"outputId":"2d24f479-df82-4ffe-948d-f663e57ee5d9"},"source":["scores = interpreter.get_tensor(output_details['index'])[0]\n","print(\"Predicted class label score      =\", scores)\n","\n","# Dequantize the scores.\n","scale, zero_point = output_details['quantization']\n","scores_dequantized = scale * (scores - zero_point)\n","\n","dequantized_max_score = np.max(np.unique(scores_dequantized))\n","print(\"Predicted class label probability=\", dequantized_max_score, end=\"\\n\\n\")\n","\n","max_score_index = np.where(scores_dequantized == np.max(np.unique(scores_dequantized)))[0][0]\n","print(\"Predicted class label ID=\", max_score_index)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted class label score      = [-0.3924779  -0.61533105 -0.38830632 -0.7587749   0.00855257  0.17836642\n"," -0.4054675   0.07680191  0.31618685  0.12227918 -0.1346258   0.47212696\n","  0.7974835  -0.4784628   0.08353613  0.06641154  0.19183695 -0.1461007\n","  0.48263103 -0.32647046 -0.20713109  0.03767988 -0.43286973  0.65035117\n","  0.64513993 -0.11419365  0.70495105  0.47103795  0.10702264 -0.26112962\n"," -0.29283637  0.56447315  0.0562494  -0.17123678  0.11072064  0.28937358\n"," -0.61507374  0.0942647   0.05319312  0.32348433  0.11744931  0.5563197\n","  0.2547111   0.63050723  0.10429575 -0.76915884 -0.31096667 -0.5002446\n","  0.16367367  0.21693747 -1.2741048   0.32102162 -0.22391573 -0.03635935\n"," -0.06962863  0.22050901  0.31553552 -0.27283588 -0.83031255 -0.86372954\n"," -0.36697015 -0.08467358 -0.40347418 -0.12438847 -0.2927877   0.9167509\n","  0.01888788  0.21836412 -0.09662464 -0.7417272   0.03524625  0.25453192\n"," -0.00859736 -0.22690386  0.48334813 -0.6610388  -0.6886684  -0.37541366\n"," -0.31934905  0.32225484  0.09469301  0.02841982 -0.22447525  0.30870226\n","  0.81880194  0.46584654  0.28511286  0.12096578 -0.5763679   0.96126705\n","  0.36419827 -0.19831182 -0.31849307 -0.07975391  0.2995747   1.0263911\n"," -0.8741166  -0.1359445  -0.74695    -0.2069229   0.01102177  0.18108204\n","  0.36251286 -0.9539901  -0.3679194  -0.36883342 -0.42341775 -0.03397216\n","  0.2654719  -0.6381707   0.62395746 -0.21246901  0.29732773  0.4324631\n","  0.0595742   0.38344583  0.08430994  0.20687845  0.6609617   0.2823978\n","  0.44951367  0.06805278  0.38338962 -0.33921188  0.4145379  -0.47637624\n","  0.5515168   0.08108575]\n","Predicted class label probability= -0.0\n","\n","Predicted class label ID= 0\n"]}]},{"cell_type":"code","metadata":{"id":"8jQGZ0wqcYJG"},"source":["from tflite_runtime.interpreter import Interpreter \n","from PIL import Image\n","import numpy as np\n","import time\n","import matplotlib.pyplot"],"execution_count":null,"outputs":[]}]}